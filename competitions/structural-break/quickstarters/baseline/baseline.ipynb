{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvWIItAe-0fN"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/crunchdao/quickstarters/blob/master/competitions/structural-break/quickstarters/baseline/baseline.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNUXnJa_-0fO"
      },
      "source": [
        "![Banner](https://raw.githubusercontent.com/crunchdao/quickstarters/refs/heads/master/competitions/structural-break/assets/banner.webp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lurIF1Ve-0fP"
      },
      "source": [
        "# ADIA Lab Structural Break Challenge\n",
        "\n",
        "## Challenge Overview\n",
        "\n",
        "Welcome to the ADIA Lab Structural Break Challenge! In this challenge, you will analyze univariate time series data to determine whether a structural break has occurred at a specified boundary point.\n",
        "\n",
        "### What is a Structural Break?\n",
        "\n",
        "A structural break occurs when the process governing the data generation changes at a certain point in time. These changes can be subtle or dramatic, and detecting them accurately is crucial across various domains such as climatology, industrial monitoring, finance, and healthcare.\n",
        "\n",
        "![Structural Break Example](https://raw.githubusercontent.com/crunchdao/competitions/refs/heads/master/competitions/structural-break/quickstarters/baseline/images/example.png)\n",
        "\n",
        "### Your Task\n",
        "\n",
        "For each time series in the test set, you need to predict a score between `0` and `1`:\n",
        "- Values closer to `0` indicate no structural break at the specified boundary point;\n",
        "- Values closer to `1` indicate a structural break did occur.\n",
        "\n",
        "### Evaluation Metric\n",
        "\n",
        "The evaluation metric is [ROC AUC (Area Under the Receiver Operating Characteristic Curve)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html), which measures the performance of detection algorithms regardless of their specific calibration.\n",
        "\n",
        "- ROC AUC around `0.5`: No better than random chance;\n",
        "- ROC AUC approaching `1.0`: Perfect detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-UrlmpOMnQw"
      },
      "source": [
        "# Setup\n",
        "\n",
        "The first steps to get started are:\n",
        "1. Get the setup command\n",
        "2. Execute it in the cell below\n",
        "\n",
        "### >> https://hub.crunchdao.com/competitions/structural-break/submit/notebook\n",
        "\n",
        "![Reveal token](https://raw.githubusercontent.com/crunchdao/competitions/refs/heads/master/documentation/animations/reveal-token.gif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DUeixiC_IJM",
        "outputId": "db78f393-2bae-46e0-bb21-16a2015ea910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "crunch-cli, version 6.5.0\n",
            "delete /content/.crunchdao\n",
            "main.py: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/submissions/21798/main.py (12366 bytes)\n",
            "notebook.ipynb: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/submissions/21798/notebook.ipynb (55168 bytes)\n",
            "requirements.txt: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/submissions/21798/requirements.original.txt (222 bytes)\n",
            "data/X_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/X_train.parquet (204327238 bytes)\n",
            "data/X_test.reduced.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/X_test.reduced.parquet (2380918 bytes)\n",
            "data/y_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/y_train.parquet (61003 bytes)\n",
            "data/y_test.reduced.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/y_test.reduced.parquet (2655 bytes)\n",
            "                                \n",
            "---\n",
            "Success! Your environment has been correctly setup.\n",
            "Next recommended actions:\n",
            "1. Load the Crunch Toolings: `crunch = crunch.load_notebook()`\n",
            "2. Execute the cells with your code\n",
            "3. Run a test: `crunch.test()`\n",
            "4. Download and submit your code to the platform!\n"
          ]
        }
      ],
      "source": [
        "%pip install crunch-cli --upgrade --quiet --progress-bar off\n",
        "!crunch setup-notebook structural-break XYSTlFGgHTHExFaBYwUyEgKo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ttest_ind\n",
        "from scipy.stats import t\n",
        "import time\n",
        "from multiprocessing import Pool, cpu_count\n",
        "from scipy.stats import shapiro\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from scipy.stats import skew, kurtosis, iqr, ttest_ind, ks_2samp\n",
        "# from pykalman import KalmanFilter\n",
        "import scipy\n",
        "\n",
        "import joblib\n",
        "import typing\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "# ---------------- Custom Transformer ----------------\n",
        "from multiprocessing import Pool, cpu_count\n",
        "import warnings"
      ],
      "metadata": {
        "id": "utRx8ZFoNM9F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IBhw7hv-0fQ"
      },
      "source": [
        "# Your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpLeMWSw-0fQ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-18T09:52:21.302334Z",
          "start_time": "2024-11-18T09:52:18.268241Z"
        },
        "id": "MKqz-6Zw-0fR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import typing\n",
        "\n",
        "# Import your dependencies\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import sklearn.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjD_WSAS-0fR",
        "outputId": "e6c465b9-2260-4d29-b8be-e15dfd0c6da5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded inline runner with module: <module '__main__'>\n",
            "\n",
            "cli version: 6.5.0\n",
            "available ram: 12.67 gb\n",
            "available cpu: 2 core\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "import crunch\n",
        "\n",
        "# Load the Crunch Toolings\n",
        "crunch = crunch.load_notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiKJODFx-0fR"
      },
      "source": [
        "## Understanding the Data\n",
        "\n",
        "The dataset consists of univariate time series, each containing ~2,000-5,000 values with a designated boundary point. For each time series, you need to determine whether a structural break occurred at this boundary point.\n",
        "\n",
        "The data was downloaded when you setup your local environment and is now available in the `data/` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKHXgvjN-0fS",
        "outputId": "b684b8e9-650b-41c9-ee4d-0cdec8c84522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/X_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/X_train.parquet (204327238 bytes)\n",
            "data/X_train.parquet: already exists, file length match\n",
            "data/X_test.reduced.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/X_test.reduced.parquet (2380918 bytes)\n",
            "data/X_test.reduced.parquet: already exists, file length match\n",
            "data/y_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/y_train.parquet (61003 bytes)\n",
            "data/y_train.parquet: already exists, file length match\n",
            "data/y_test.reduced.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/y_test.reduced.parquet (2655 bytes)\n",
            "data/y_test.reduced.parquet: already exists, file length match\n"
          ]
        }
      ],
      "source": [
        "# Load the data simply\n",
        "X_train, y_train, X_test = crunch.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T_JmgMq-0fS"
      },
      "source": [
        "### Understanding `X_train`\n",
        "\n",
        "The training data is structured as a pandas DataFrame with a MultiIndex:\n",
        "\n",
        "**Index Levels:**\n",
        "- `id`: Identifies the unique time series\n",
        "- `time`: The timestep within each time series\n",
        "\n",
        "**Columns:**\n",
        "- `value`: The actual time series value at each timestep\n",
        "- `period`: A binary indicator where `0` represents the **period before** the boundary point, and `1` represents the **period after** the boundary point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WP39dgx-0fS"
      },
      "source": [
        "### Understanding `y_train`\n",
        "\n",
        "This is a simple `pandas.Series` that tells if a dataset id has a structural breakpoint or not.\n",
        "\n",
        "**Index:**\n",
        "- `id`: the ID of the dataset\n",
        "\n",
        "**Value:**\n",
        "- `structural_breakpoint`: Boolean indicating whether a structural break occurred (`True`) or not (`False`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oSS08Ks-0fT"
      },
      "source": [
        "### Understanding `X_test`\n",
        "\n",
        "The test data is provided as a **`list` of `pandas.DataFrame`s** with the same format as [`X_train`](#understanding-X_test).\n",
        "\n",
        "It is structured as a list to encourage processing records one by one, which will be mandatory in the `infer()` function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgulFOGX-0fT"
      },
      "source": [
        "## Strategy Implementation\n",
        "\n",
        "There are multiple approaches you can take to detect structural breaks:\n",
        "\n",
        "1. **Statistical Tests**: Compare distributions before and after the boundary point;\n",
        "2. **Feature Engineering**: Extract features from both segments for comparison;\n",
        "3. **Time Series Modeling**: Detect deviations from expected patterns;\n",
        "4. **Machine Learning**: Train models to recognize break patterns from labeled examples.\n",
        "\n",
        "The baseline implementation below uses a simple statistical approach: a t-test to compare the distributions before and after the boundary point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLfYIXlz-0fT"
      },
      "source": [
        "### The `train()` Function\n",
        "\n",
        "In this function, you build and train your model for making inferences on the test data. Your model must be stored in the `model_directory_path`.\n",
        "\n",
        "The baseline implementation below doesn't require a pre-trained model, as it uses a statistical test that will be computed at inference time."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XfS9zOMWBRPj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices_x = X_train.index.get_level_values(0).unique().tolist()\n",
        "indices_x.sort()"
      ],
      "metadata": {
        "id": "E_N2uz3UOBxM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kalman_stats(series):\n",
        "    kf = KalmanFilter(initial_state_mean=0, n_dim_obs=1)\n",
        "    # fewer EM iterations\n",
        "    kf = kf.em(series, n_iter=1)\n",
        "    state_means, _ = kf.smooth(series)\n",
        "    state_means = state_means.flatten()\n",
        "\n",
        "    smoothed_mean = np.mean(state_means)\n",
        "    smoothed_std = np.std(state_means)\n",
        "    residual = series - state_means\n",
        "    residual_std = np.std(residual)\n",
        "    trend_strength = smoothed_std / (np.std(series) + 1e-6)\n",
        "\n",
        "    return {\n",
        "        'kf_mean': smoothed_mean,\n",
        "        'kf_std': smoothed_std,\n",
        "        'kf_residual_std': residual_std,\n",
        "        'kf_trend_strength': trend_strength\n",
        "    }\n",
        "\n",
        "def ou_process_params(series):\n",
        "    X = series[:-1].reshape(-1, 1)\n",
        "    Y = series[1:].reshape(-1,1)\n",
        "\n",
        "    meanX = np.mean(X)\n",
        "    meanY = np.mean(Y)\n",
        "    varX = np.var(X)\n",
        "    varY = np.var(Y)\n",
        "    CovXY = np.mean((X-meanX)*(Y-meanY))\n",
        "    R2 = CovXY**2/(varX*varY)\n",
        "\n",
        "    beta = CovXY/varX\n",
        "    cs = (meanY - beta*meanX)\n",
        "\n",
        "\n",
        "    kappa = -np.log(abs(beta))\n",
        "    mu = (cs/(1-beta+0.000001))\n",
        "\n",
        "    residuals = Y - beta*X - cs\n",
        "    sigma_hat = np.std(residuals, ddof=1)\n",
        "    sigma_squaroot = (sigma_hat) / np.sqrt(1 - beta ** 2 + 0.000001)\n",
        "\n",
        "    return kappa, mu, sigma_squaroot\n",
        "\n",
        "\n",
        "def find_d(series, max_d=2):\n",
        "    series = pd.Series(series)\n",
        "\n",
        "    for d in range(max_d + 1):\n",
        "        diffed = series.diff(d).dropna()\n",
        "\n",
        "        # Skip if constant or too short\n",
        "        if diffed.nunique() <= 1 or len(diffed) < 10:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            p_value = adfuller(diffed)[1]\n",
        "            if p_value < 0.05:\n",
        "                return d\n",
        "        except ValueError:\n",
        "            continue  # Skip constant series or bad input\n",
        "\n",
        "    return max_d  # fallback\n",
        "\n",
        "def find_best_arima_coeffs(series, max_p=1, max_q=1, d=None):\n",
        "\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    if d is None:\n",
        "        d = find_d(series)\n",
        "\n",
        "    best_aic = np.inf\n",
        "    best_order = None\n",
        "    best_model = None\n",
        "\n",
        "    for p in range(max_p + 1):\n",
        "        for q in range(max_q + 1):\n",
        "            try:\n",
        "                model = ARIMA(series, order=(p, d, q)).fit()\n",
        "                if model.aic < best_aic:\n",
        "                    best_aic = model.aic\n",
        "                    best_order = (p, d, q)\n",
        "                    best_model = model\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    if best_order is None:\n",
        "        return None, [0],0, [0], None\n",
        "\n",
        "    p, d, q = best_order\n",
        "\n",
        "    # Extract AR (phi) and MA (theta) coefficients\n",
        "    params = best_model.arparams if p > 0 else []\n",
        "    p_vec = list(params[:1]) + [0.0] * (1 - len(params))\n",
        "\n",
        "    params = best_model.maparams if q > 0 else []\n",
        "    q_vec = list(params[:1]) + [0.0] * (1 - len(params))\n",
        "\n",
        "    return best_order, p_vec, d, q_vec, best_model\n",
        "\n",
        "\n",
        "\n",
        "def fast_ema(x, span):\n",
        "    alpha = 2/(span+1)\n",
        "    ema = np.empty_like(x)\n",
        "    ema[0] = x[0]\n",
        "    for i in range(1, len(x)):\n",
        "        ema[i] = alpha * x[i] + (1-alpha) * ema[i-1]\n",
        "    return ema[-1]\n",
        "\n",
        "def extract_features(a, b):\n",
        "    features = {}\n",
        "\n",
        "    # Basic statistics\n",
        "    features['mean_a'] = np.mean(a)\n",
        "    features['mean_b'] = np.mean(b)\n",
        "    features['std_a'] = np.std(a)\n",
        "    features['std_b'] = np.std(b)\n",
        "    features['skew_a'] = skew(a)\n",
        "    features['skew_b'] = skew(b)\n",
        "    features['kurt_a'] = kurtosis(a)\n",
        "    features['kurt_b'] = kurtosis(b)\n",
        "    features['iqr_a'] = iqr(a)\n",
        "    features['iqr_b'] = iqr(b)\n",
        "    features['std_ratio'] = features['std_b'] / (features['std_a'] + 1e-10)  # avoid div0\n",
        "\n",
        "    # Fit t-distribution (consider sampling if large arrays)\n",
        "    params_a = scipy.stats.t.fit(a)\n",
        "    params_b = scipy.stats.t.fit(b)\n",
        "    features['t_val_a'] = params_a[0]\n",
        "    features['t_mu_a'] = params_a[1]\n",
        "    features['t_sigma_a'] = params_a[2]\n",
        "    features['t_val_b'] = params_b[0]\n",
        "    features['t_mu_b'] = params_b[1]\n",
        "    features['t_sigma_b'] = params_b[2]\n",
        "\n",
        "    # Differences\n",
        "    features['mean_diff'] = features['mean_b'] - features['mean_a']\n",
        "    features['std_diff'] = features['std_b'] - features['std_a']\n",
        "\n",
        "    # Statistical tests\n",
        "    features['ttest_p'] = ttest_ind(a, b, equal_var=False).pvalue\n",
        "    features['ks_p'] = ks_2samp(a, b).pvalue\n",
        "\n",
        "    result0 = adfuller(a)\n",
        "    result1 = adfuller(b)\n",
        "\n",
        "    if result0[1] < 0.05:\n",
        "        features['mean_reverting_0'] = 1\n",
        "        features['kappa_0'],features['mu_0'],features['var_0'] = ou_process_params(a)\n",
        "\n",
        "\n",
        "    else:\n",
        "        features['mean_reverting_0'] = 0\n",
        "        features['kappa_0'],features['mu_0'],features['var_0'] = 0,0,0\n",
        "\n",
        "    # best_order, p_vec, d, q_vec, best_model = find_best_arima_coeffs(a)\n",
        "    # for i in range(1):\n",
        "    #     features[f'arima0_p{i}'] = p_vec[i]\n",
        "    #     features[f'arima0_q{i}'] = q_vec[i]\n",
        "    #     features['arima0_d'] = d\n",
        "\n",
        "    # best_order, p_vec, d, q_vec, best_model = find_best_arima_coeffs(b)\n",
        "    # for i in range(1):\n",
        "    #     features[f'arima1_p{i}'] = p_vec[i]\n",
        "    #     features[f'arima_p{i}_diff'] = features[f'arima0_p{i}'] - p_vec[i]\n",
        "    #     features[f'arima1_q{i}'] = q_vec[i]\n",
        "    #     features[f'arima_q{i}_diff'] = features[f'arima0_q{i}'] - p_vec[i]\n",
        "    #     features['arima1_d'] = d\n",
        "    #     features['arima1_d_diff'] = features['arima0_d'] - d\n",
        "\n",
        "    if result1[1] < 0.05:\n",
        "        features['mean_reverting_1'] = 1\n",
        "        features['kappa_1'],features['mu_1'],features['var_1'] = ou_process_params(b)\n",
        "    else:\n",
        "        features['mean_reverting_1'] = 0\n",
        "        features['kappa_1'],features['mu_1'],features['var_1'] = 0,0,0\n",
        "\n",
        "    # Kalman features\n",
        "    # try:\n",
        "\n",
        "    #   kf_a = kalman_stats(np.array(a))\n",
        "    #   kf_b = kalman_stats(np.array(b))\n",
        "    #   for k, v in kf_a.items():\n",
        "    #       features[f'{k}_a'] = v\n",
        "    #   for k, v in kf_b.items():\n",
        "    #       features[f'{k}_b'] = v\n",
        "    #   features['kf_trend_strength_diff'] = features['kf_trend_strength_b'] - features['kf_trend_strength_a']\n",
        "\n",
        "    # except:\n",
        "    #   pass\n",
        "\n",
        "    # EMA features (use fast_ema)\n",
        "    ema_windows = [5, 10, 15, 20, 25]\n",
        "    for w in ema_windows:\n",
        "        ema_a = fast_ema(a, w)\n",
        "        ema_b = fast_ema(b, w)\n",
        "        features[f'ema{w}_a'] = ema_a\n",
        "        features[f'ema{w}_b'] = ema_b\n",
        "        features[f'ema{w}_diff'] = ema_b - ema_a\n",
        "\n",
        "    # Cross-correlation\n",
        "    min_len = min(len(a), len(b))\n",
        "    a = a[:min_len]\n",
        "    b = b[:min_len]\n",
        "    max_lag = min(10, min_len - 1)\n",
        "    xcorr = []\n",
        "    for lag in range(1, max_lag + 1):\n",
        "        corr = np.corrcoef(a[:-lag], b[lag:])[0, 1]\n",
        "        xcorr.append(corr)\n",
        "\n",
        "    features['max_xcorr'] = np.nanmax(xcorr)\n",
        "    features['mean_xcorr'] = np.nanmean(xcorr)\n",
        "\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "qOaMDCPuCZZI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_x = X_train.index.get_level_values(0).unique().tolist()\n",
        "len(index_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIY1lKdmC4Pf",
        "outputId": "31fafd41-af58-4987-e909-397ea96aa9af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10001"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-18T10:04:00.459399Z",
          "start_time": "2024-11-18T10:04:00.455716Z"
        },
        "id": "xQwWDC6M-0fT"
      },
      "outputs": [],
      "source": [
        "def process_chunk(temp):\n",
        "  t0_series = temp[temp.period == 0].value.values\n",
        "  t1_series = temp[temp.period == 1].value.values\n",
        "  features_v = extract_features(t0_series, t1_series)\n",
        "  return features_v\n",
        "\n",
        "def process_wrapper(i_X):\n",
        "    i, X = i_X\n",
        "    if i%100 == 0:\n",
        "        print(f\"presently running {i} data item to extract\")\n",
        "    return i, process_chunk(X.loc[i])\n",
        "\n",
        "\n",
        "\n",
        "def train(\n",
        "    X_train: pd.DataFrame,\n",
        "    y_train: pd.Series,\n",
        "    model_directory_path: str,\n",
        "):\n",
        "    os.makedirs(model_directory_path, exist_ok=True)\n",
        "\n",
        "    # try:\n",
        "    #   !pip install pykalman\n",
        "    # except:\n",
        "    #   pass\n",
        "\n",
        "\n",
        "\n",
        "    # For our baseline t-test approach, we don't need to train a model\n",
        "    # This is essentially an unsupervised approach calculated at inference time\n",
        "    #data_file = os.path.join(model_directory_path,\"data.csv\")\n",
        "\n",
        "    index_x = X_train.index.get_level_values(0).unique().tolist()\n",
        "\n",
        "    print(f\"Spawning {cpu_count()} parallel workers...\")\n",
        "\n",
        "    # Prepare iterable of (i, X) tuples\n",
        "    args = [(i, X_train) for i in index_x]\n",
        "\n",
        "    with Pool(processes=cpu_count()) as pool:\n",
        "        results = list(pool.imap_unordered(process_wrapper, args, chunksize=10))\n",
        "\n",
        "    # Unpack results\n",
        "    index_x, features_list = zip(*results)\n",
        "\n",
        "    data = pd.DataFrame.from_records(features_list, index=index_x)\n",
        "\n",
        "    data.index.name = \"time\"\n",
        "\n",
        "    print(f\"shape of data is {data.shape} and len is {len(index_x)}\")\n",
        "      # data.to_csv(data_file)\n",
        "\n",
        "    base_model = XGBClassifier(\n",
        "    eval_metric='auc',\n",
        "    random_state=42,\n",
        "\n",
        ")\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', base_model)\n",
        "    ])\n",
        "\n",
        "    param_grid = {\n",
        "        'clf__n_estimators': [100, 200, 300],\n",
        "        'clf__max_depth': [5, 10],\n",
        "        'clf__learning_rate': [0.01, 0.1,0.2],\n",
        "        'clf__subsample': [0.8, 1.0],\n",
        "        'clf__colsample_bytree': [0.8, 1.0]\n",
        "    }\n",
        "\n",
        "    grid = GridSearchCV(\n",
        "        estimator=pipeline,\n",
        "        param_grid=param_grid,\n",
        "        scoring='roc_auc',\n",
        "        cv=3,\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    grid.fit(data, y_train)\n",
        "\n",
        "    best_model = grid.best_estimator_\n",
        "    os.makedirs(model_directory_path, exist_ok=True)\n",
        "    #best_model.save_model('model.json')\n",
        "    joblib.dump(best_model, os.path.join(model_directory_path, 'model.joblib'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n-jboJH-0fU"
      },
      "source": [
        "### The `infer()` Function\n",
        "\n",
        "In the inference function, your trained model (if any) is loaded and used to make predictions on test data.\n",
        "\n",
        "**Important workflow:**\n",
        "1. Load your model;\n",
        "2. Use the `yield` statement to signal readiness to the runner;\n",
        "3. Process each dataset one by one within the for loop;\n",
        "4. For each dataset, use `yield prediction` to return your prediction.\n",
        "\n",
        "**Note:** The datasets can only be iterated once!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-18T10:03:59.120294Z",
          "start_time": "2024-11-18T10:03:59.114830Z"
        },
        "id": "r1b7hRkl-0fU"
      },
      "outputs": [],
      "source": [
        "# def infer(\n",
        "#     X_test: typing.Iterable[pd.DataFrame],\n",
        "#     model_directory_path: str,\n",
        "# ):\n",
        "#     model = joblib.load(os.path.join(model_directory_path, 'model.joblib'))\n",
        "\n",
        "#     yield  # Mark as ready\n",
        "\n",
        "#     # X_test can only be iterated once.\n",
        "#     # Before getting the next dataset, you must predict the current one.\n",
        "#     for dataset in X_test:\n",
        "#         # Baseline approach: Compute t-test between values before and after boundary point\n",
        "#         # The negative p-value is used as our score - smaller p-values (larger negative numbers)\n",
        "#         # indicate more evidence against the null hypothesis that distributions are the same,\n",
        "#         # suggesting a structural break\n",
        "#         def t_test(u: pd.DataFrame):\n",
        "#             return -scipy.stats.ttest_ind(\n",
        "#                 u[\"value\"][u[\"period\"] == 0],  # Values before boundary point\n",
        "#                 u[\"value\"][u[\"period\"] == 1],  # Values after boundary point\n",
        "#             ).pvalue\n",
        "\n",
        "#         prediction = t_test(dataset)\n",
        "#         yield prediction  # Send the prediction for the current dataset\n",
        "\n",
        "#         # Note: This baseline approach uses a t-test to compare the distributions\n",
        "#         # before and after the boundary point. A smaller p-value (larger negative number)\n",
        "#         # suggests stronger evidence that the distributions are different,\n",
        "#         # indicating a potential structural break.\n",
        "\n",
        "\n",
        "def infer(\n",
        "    X_test: typing.Iterable[pd.DataFrame],\n",
        "    model_directory_path: str,\n",
        "):\n",
        "    # try:\n",
        "    #   !pip install pykalman\n",
        "    # except:\n",
        "    #   pass\n",
        "    # Load the trained model\n",
        "    model = joblib.load(os.path.join(model_directory_path, 'model.joblib'))\n",
        "\n",
        "    yield  # Mark as ready for inference\n",
        "\n",
        "    for dataset in X_test:\n",
        "        # Feature extraction using the same logic as in training\n",
        "        features = process_chunk(dataset)\n",
        "        features_df = pd.DataFrame([features])\n",
        "\n",
        "        # Predict probability of the positive class (1)\n",
        "        prediction = model.predict_proba(features_df)[0, 1]\n",
        "\n",
        "        yield prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W0Kl9CA-0fU"
      },
      "source": [
        "## Local testing\n",
        "\n",
        "To make sure your `train()` and `infer()` function are working properly, you can call the `crunch.test()` function that will reproduce the cloud environment locally. <br />\n",
        "Even if it is not perfect, it should give you a quick idea if your model is working properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDZeP-4--0fU",
        "outputId": "59164112-7981-4013-e24f-16fe6e703d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18:39:04 no forbidden library found\n",
            "18:39:04 \n",
            "18:39:04 started\n",
            "18:39:04 running local test\n",
            "18:39:04 internet access isn't restricted, no check will be done\n",
            "18:39:04 \n",
            "18:39:06 starting unstructured loop...\n",
            "18:39:06 executing - command=train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/X_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/X_train.parquet (204327238 bytes)\n",
            "data/X_train.parquet: already exists, file length match\n",
            "data/X_test.reduced.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/X_test.reduced.parquet (2380918 bytes)\n",
            "data/X_test.reduced.parquet: already exists, file length match\n",
            "data/y_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/y_train.parquet (61003 bytes)\n",
            "data/y_train.parquet: already exists, file length match\n",
            "data/y_test.reduced.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/y_test.reduced.parquet (2655 bytes)\n",
            "data/y_test.reduced.parquet: already exists, file length match\n",
            "Spawning 2 parallel workers...\n"
          ]
        }
      ],
      "source": [
        "crunch.test(\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV_5CKs--0fU"
      },
      "source": [
        "## Results\n",
        "\n",
        "Once the local tester is done, you can preview the result stored in `data/prediction.parquet`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "ly5q68sA-0fU",
        "outputId": "b25b6c1a-80f0-4184-ae2e-34ad1892fe9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       prediction\n",
              "id               \n",
              "10001    0.250684\n",
              "10002    0.166222\n",
              "10003    0.287946\n",
              "10004    0.263036\n",
              "10005    0.246365\n",
              "...           ...\n",
              "10097    0.387867\n",
              "10098    0.273245\n",
              "10099    0.507799\n",
              "10100    0.204416\n",
              "10101    0.287652\n",
              "\n",
              "[101 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c609ffd-7aa0-4ba7-b0cd-55aa8589e8d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10001</th>\n",
              "      <td>0.250684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10002</th>\n",
              "      <td>0.166222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10003</th>\n",
              "      <td>0.287946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10004</th>\n",
              "      <td>0.263036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10005</th>\n",
              "      <td>0.246365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10097</th>\n",
              "      <td>0.387867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10098</th>\n",
              "      <td>0.273245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10099</th>\n",
              "      <td>0.507799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10100</th>\n",
              "      <td>0.204416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10101</th>\n",
              "      <td>0.287652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c609ffd-7aa0-4ba7-b0cd-55aa8589e8d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c609ffd-7aa0-4ba7-b0cd-55aa8589e8d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c609ffd-7aa0-4ba7-b0cd-55aa8589e8d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ee5ca49b-6576-4d15-a1c7-c13094915f10\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee5ca49b-6576-4d15-a1c7-c13094915f10')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ee5ca49b-6576-4d15-a1c7-c13094915f10 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c1de8a5e-986a-454e-9def-798d0f5c6a1e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('prediction')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c1de8a5e-986a-454e-9def-798d0f5c6a1e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('prediction');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "prediction",
              "summary": "{\n  \"name\": \"prediction\",\n  \"rows\": 101,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 10001,\n        \"max\": 10101,\n        \"num_unique_values\": 101,\n        \"samples\": [\n          10085,\n          10056,\n          10067\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prediction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09435371601071807,\n        \"min\": 0.16622155904769897,\n        \"max\": 0.575056791305542,\n        \"num_unique_values\": 101,\n        \"samples\": [\n          0.5206701755523682,\n          0.3126005530357361,\n          0.3517017960548401\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "prediction = pd.read_parquet(\"data/prediction.parquet\")\n",
        "prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oP-NLGh-0fU"
      },
      "source": [
        "### Local scoring\n",
        "\n",
        "You can call the function that the system uses to estimate your score locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyCrjpzv-0fU",
        "outputId": "5a523194-e7f6-45aa-dcbf-17ea2271098d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.6446009389671362)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Load the targets\n",
        "target = pd.read_parquet(\"data/y_test.reduced.parquet\")[\"structural_breakpoint\"]\n",
        "\n",
        "# Call the scoring function\n",
        "sklearn.metrics.roc_auc_score(\n",
        "    target,\n",
        "    prediction,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AE1i3pR-0fV"
      },
      "source": [
        "# Submit your Notebook\n",
        "\n",
        "To submit your work, you must:\n",
        "1. Download your Notebook from Colab\n",
        "2. Upload it to the platform\n",
        "3. Create a run to validate it\n",
        "\n",
        "### >> https://hub.crunchdao.com/competitions/structural-break/submit/notebook\n",
        "\n",
        "![Download and Submit Notebook](https://raw.githubusercontent.com/crunchdao/competitions/refs/heads/master/documentation/animations/download-and-submit-notebook.gif)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}