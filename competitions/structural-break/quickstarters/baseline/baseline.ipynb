{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvWIItAe-0fN"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/crunchdao/quickstarters/blob/master/competitions/structural-break/quickstarters/baseline/baseline.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNUXnJa_-0fO"
      },
      "source": [
        "![Banner](https://raw.githubusercontent.com/crunchdao/quickstarters/refs/heads/master/competitions/structural-break/assets/banner.webp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lurIF1Ve-0fP"
      },
      "source": [
        "# ADIA Lab Structural Break Challenge\n",
        "\n",
        "## Challenge Overview\n",
        "\n",
        "Welcome to the ADIA Lab Structural Break Challenge! In this challenge, you will analyze univariate time series data to determine whether a structural break has occurred at a specified boundary point.\n",
        "\n",
        "### What is a Structural Break?\n",
        "\n",
        "A structural break occurs when the process governing the data generation changes at a certain point in time. These changes can be subtle or dramatic, and detecting them accurately is crucial across various domains such as climatology, industrial monitoring, finance, and healthcare.\n",
        "\n",
        "![Structural Break Example](https://raw.githubusercontent.com/crunchdao/competitions/refs/heads/master/competitions/structural-break/quickstarters/baseline/images/example.png)\n",
        "\n",
        "### Your Task\n",
        "\n",
        "For each time series in the test set, you need to predict a score between `0` and `1`:\n",
        "- Values closer to `0` indicate no structural break at the specified boundary point;\n",
        "- Values closer to `1` indicate a structural break did occur.\n",
        "\n",
        "### Evaluation Metric\n",
        "\n",
        "The evaluation metric is [ROC AUC (Area Under the Receiver Operating Characteristic Curve)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html), which measures the performance of detection algorithms regardless of their specific calibration.\n",
        "\n",
        "- ROC AUC around `0.5`: No better than random chance;\n",
        "- ROC AUC approaching `1.0`: Perfect detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq_0R764Dc3s"
      },
      "source": [
        "# Setup\n",
        "\n",
        "The first steps to get started are:\n",
        "1. Get the setup command\n",
        "2. Execute it in the cell below\n",
        "\n",
        "### >> https://hub.crunchdao.com/competitions/structural-break/submit/notebook\n",
        "\n",
        "![Reveal token](https://raw.githubusercontent.com/crunchdao/competitions/refs/heads/master/documentation/animations/reveal-token.gif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DUeixiC_IJM",
        "outputId": "c786b575-c31d-44d2-884e-fe44f517f65d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "crunch-cli, version 6.6.1\n",
            "main.py: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/submissions/22801/main.py (20912 bytes)\n",
            "notebook.ipynb: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/submissions/22801/notebook.ipynb (244244 bytes)\n",
            "requirements.txt: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/submissions/22801/requirements.original.txt (265 bytes)\n",
            "data/X_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/X_train.parquet (204327238 bytes)\n",
            "data/X_test.reduced.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/X_test.reduced.parquet (2380918 bytes)\n",
            "data/y_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/y_train.parquet (61003 bytes)\n",
            "data/y_test.reduced.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/y_test.reduced.parquet (2655 bytes)\n",
            "                                \n",
            "---\n",
            "Success! Your environment has been correctly setup.\n",
            "Next recommended actions:\n",
            "1. Load the Crunch Toolings: `crunch = crunch.load_notebook()`\n",
            "2. Execute the cells with your code\n",
            "3. Run a test: `crunch.test()`\n",
            "4. Download and submit your code to the platform!\n"
          ]
        }
      ],
      "source": [
        "%pip install crunch-cli --upgrade --quiet --progress-bar off\n",
        "!crunch setup-notebook structural-break hmvU5fVOooo2bQ0onxDzg0uo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IBhw7hv-0fQ"
      },
      "source": [
        "# Your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpLeMWSw-0fQ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-18T09:52:21.302334Z",
          "start_time": "2024-11-18T09:52:18.268241Z"
        },
        "id": "MKqz-6Zw-0fR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import typing\n",
        "\n",
        "# Import your dependencies\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import sklearn.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjD_WSAS-0fR",
        "outputId": "b2679f3c-d916-48be-9f38-4c0a8215ff57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded inline runner with module: <module '__main__'>\n",
            "\n",
            "cli version: 6.6.1\n",
            "available ram: 12.67 gb\n",
            "available cpu: 2 core\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "import crunch\n",
        "\n",
        "# Load the Crunch Toolings\n",
        "crunch = crunch.load_notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiKJODFx-0fR"
      },
      "source": [
        "## Understanding the Data\n",
        "\n",
        "The dataset consists of univariate time series, each containing ~2,000-5,000 values with a designated boundary point. For each time series, you need to determine whether a structural break occurred at this boundary point.\n",
        "\n",
        "The data was downloaded when you setup your local environment and is now available in the `data/` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKHXgvjN-0fS",
        "outputId": "396f86e4-3672-40b9-c56d-703897b0a284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/X_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/X_train.parquet (204327238 bytes)\n",
            "data/X_train.parquet: already exists, file length match\n",
            "data/X_test.reduced.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/X_test.reduced.parquet (2380918 bytes)\n",
            "data/X_test.reduced.parquet: already exists, file length match\n",
            "data/y_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/y_train.parquet (61003 bytes)\n",
            "data/y_train.parquet: already exists, file length match\n",
            "data/y_test.reduced.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/y_test.reduced.parquet (2655 bytes)\n",
            "data/y_test.reduced.parquet: already exists, file length match\n"
          ]
        }
      ],
      "source": [
        "# Load the data simply\n",
        "X_train, y_train, X_test = crunch.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T_JmgMq-0fS"
      },
      "source": [
        "### Understanding `X_train`\n",
        "\n",
        "The training data is structured as a pandas DataFrame with a MultiIndex:\n",
        "\n",
        "**Index Levels:**\n",
        "- `id`: Identifies the unique time series\n",
        "- `time`: The timestep within each time series\n",
        "\n",
        "**Columns:**\n",
        "- `value`: The actual time series value at each timestep\n",
        "- `period`: A binary indicator where `0` represents the **period before** the boundary point, and `1` represents the **period after** the boundary point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "0oRCTnOb-0fS",
        "outputId": "bfbf25f7-5806-4d25-dc11-b24d27db4e03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               value  period\n",
              "id    time                  \n",
              "0     0    -0.005564       0\n",
              "      1     0.003705       0\n",
              "      2     0.013164       0\n",
              "      3     0.007151       0\n",
              "      4    -0.009979       0\n",
              "...              ...     ...\n",
              "10000 2134  0.001137       1\n",
              "      2135  0.003526       1\n",
              "      2136  0.000687       1\n",
              "      2137  0.001640       1\n",
              "      2138  0.001074       1\n",
              "\n",
              "[23715734 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20f222c6-553c-46fa-87fc-966af70a515a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>value</th>\n",
              "      <th>period</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
              "      <th>0</th>\n",
              "      <td>-0.005564</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.003705</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.013164</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.007151</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.009979</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">10000</th>\n",
              "      <th>2134</th>\n",
              "      <td>0.001137</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2135</th>\n",
              "      <td>0.003526</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2136</th>\n",
              "      <td>0.000687</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2137</th>\n",
              "      <td>0.001640</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2138</th>\n",
              "      <td>0.001074</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23715734 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20f222c6-553c-46fa-87fc-966af70a515a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-20f222c6-553c-46fa-87fc-966af70a515a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-20f222c6-553c-46fa-87fc-966af70a515a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2c98f799-d451-42e9-8ee0-9964666a00ce\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c98f799-d451-42e9-8ee0-9964666a00ce')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2c98f799-d451-42e9-8ee0-9964666a00ce button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_6b5f3d04-78dc-4e9b-8f1e-ecec8c30cd58\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6b5f3d04-78dc-4e9b-8f1e-ecec8c30cd58 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WP39dgx-0fS"
      },
      "source": [
        "### Understanding `y_train`\n",
        "\n",
        "This is a simple `pandas.Series` that tells if a dataset id has a structural breakpoint or not.\n",
        "\n",
        "**Index:**\n",
        "- `id`: the ID of the dataset\n",
        "\n",
        "**Value:**\n",
        "- `structural_breakpoint`: Boolean indicating whether a structural break occurred (`True`) or not (`False`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "dPsQPdIj-0fT",
        "outputId": "a929b790-1680-47ba-fc60-948e067c1480"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "0        False\n",
              "1        False\n",
              "2         True\n",
              "3        False\n",
              "4        False\n",
              "         ...  \n",
              "9996     False\n",
              "9997     False\n",
              "9998     False\n",
              "9999     False\n",
              "10000     True\n",
              "Name: structural_breakpoint, Length: 10001, dtype: bool"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>structural_breakpoint</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10001 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> bool</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oSS08Ks-0fT"
      },
      "source": [
        "### Understanding `X_test`\n",
        "\n",
        "The test data is provided as a **`list` of `pandas.DataFrame`s** with the same format as [`X_train`](#understanding-X_test).\n",
        "\n",
        "It is structured as a list to encourage processing records one by one, which will be mandatory in the `infer()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ErbKAs--0fT",
        "outputId": "72484c9d-db0d-41bf-bf60-0304dee1a881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of datasets: 101\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of datasets:\", len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "M_dTYXms-0fT",
        "outputId": "99da9780-7055-4164-c5e4-50c10cf21a60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               value  period\n",
              "id    time                  \n",
              "10001 0     0.010753       0\n",
              "      1    -0.031915       0\n",
              "      2    -0.010989       0\n",
              "      3    -0.011111       0\n",
              "      4     0.011236       0\n",
              "...              ...     ...\n",
              "      2774 -0.013937       1\n",
              "      2775 -0.015649       1\n",
              "      2776 -0.009744       1\n",
              "      2777  0.025375       1\n",
              "      2778 -0.001515       1\n",
              "\n",
              "[2779 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-235be83e-6928-4625-9859-217cc2383301\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>value</th>\n",
              "      <th>period</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">10001</th>\n",
              "      <th>0</th>\n",
              "      <td>0.010753</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.031915</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.010989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.011111</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.011236</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>-0.013937</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2775</th>\n",
              "      <td>-0.015649</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2776</th>\n",
              "      <td>-0.009744</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2777</th>\n",
              "      <td>0.025375</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2778</th>\n",
              "      <td>-0.001515</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2779 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-235be83e-6928-4625-9859-217cc2383301')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-235be83e-6928-4625-9859-217cc2383301 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-235be83e-6928-4625-9859-217cc2383301');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-954d96c8-15b4-4e7a-90ef-2b11dbeba121\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-954d96c8-15b4-4e7a-90ef-2b11dbeba121')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-954d96c8-15b4-4e7a-90ef-2b11dbeba121 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"X_test[0]\",\n  \"rows\": 2779,\n  \"fields\": [\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02972494368757725,\n        \"min\": -0.322581,\n        \"max\": 0.176991,\n        \"num_unique_values\": 1939,\n        \"samples\": [\n          -0.00052267,\n          -0.027999999999999997,\n          -0.0256409\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"period\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "X_test[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgulFOGX-0fT"
      },
      "source": [
        "## Strategy Implementation\n",
        "\n",
        "There are multiple approaches you can take to detect structural breaks:\n",
        "\n",
        "1. **Statistical Tests**: Compare distributions before and after the boundary point;\n",
        "2. **Feature Engineering**: Extract features from both segments for comparison;\n",
        "3. **Time Series Modeling**: Detect deviations from expected patterns;\n",
        "4. **Machine Learning**: Train models to recognize break patterns from labeled examples.\n",
        "\n",
        "The baseline implementation below uses a simple statistical approach: a t-test to compare the distributions before and after the boundary point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLfYIXlz-0fT"
      },
      "source": [
        "### The `train()` Function\n",
        "\n",
        "In this function, you build and train your model for making inferences on the test data. Your model must be stored in the `model_directory_path`.\n",
        "\n",
        "The baseline implementation below doesn't require a pre-trained model, as it uses a statistical test that will be computed at inference time."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install optuna"
      ],
      "metadata": {
        "id": "-MHM40HIvwGS"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ttest_ind\n",
        "from scipy.stats import t\n",
        "import time\n",
        "from multiprocessing import Pool, cpu_count\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from scipy.stats import skew, kurtosis, iqr, ttest_ind, ks_2samp\n",
        "import scipy\n",
        "\n",
        "import joblib\n",
        "import typing\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from multiprocessing import Pool, cpu_count\n",
        "import warnings\n",
        "\n",
        "import typing\n",
        "import sklearn.metrics\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import logging\n",
        "import pickle\n",
        "import time\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "from collections import OrderedDict\n",
        "\n",
        "import math"
      ],
      "metadata": {
        "id": "AEy3CWJxEGFt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "# TorchScript-compatible Kalman filter\n",
        "@torch.jit.script\n",
        "def run_kalman_filter_script(\n",
        "    measurements: torch.Tensor,\n",
        "    F: float,\n",
        "    H: float,\n",
        "    R: float,\n",
        "    Q: float,\n",
        "    device: torch.device\n",
        ") -> torch.Tensor:\n",
        "\n",
        "    x = torch.tensor(0.0, device=measurements.device)\n",
        "    P = torch.tensor(1.0, device=measurements.device)\n",
        "    est = []\n",
        "\n",
        "    for z in measurements:\n",
        "        x = F * x\n",
        "        P = F * P * F + Q\n",
        "\n",
        "        K = P * H / (H * P * H + R)\n",
        "        x = x + K * (z - H * x)\n",
        "        P = (1 - K * H) * P\n",
        "\n",
        "        est.append(x)\n",
        "\n",
        "    return torch.stack(est)\n",
        "\n",
        "\n",
        "def extract_kalman(X_train,device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),logger=None):\n",
        "    # Main loop\n",
        "    kalman_series0 = []\n",
        "    kalman_series1 = []\n",
        "    raw_series0 = []\n",
        "    raw_series1 = []\n",
        "\n",
        "    # Assuming X_train is already defined with MultiIndex\n",
        "    index_x = X_train.index.get_level_values(0).unique()\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Kalman filter constants as tensors (still used outside JIT)\n",
        "    F = torch.tensor(1.0, device=device)\n",
        "    H = torch.tensor(1.0, device=device)\n",
        "    R = torch.tensor(1.0, device=device)\n",
        "    Q = torch.tensor(1e-5, device=device)\n",
        "\n",
        "    for i in index_x:\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Estimating Kalman series for {i}-th series, time taken: {time.time() - start_time:.2f}s\")\n",
        "            start_time = time.time()\n",
        "\n",
        "        series = X_train.loc[i]\n",
        "\n",
        "        t0 = torch.tensor(series[series.period == 0].value.values, dtype=torch.float32, device=device)\n",
        "        t1 = torch.tensor(series[series.period == 1].value.values, dtype=torch.float32, device=device)\n",
        "        raw_series0.append(t0)\n",
        "        raw_series1.append(t1)\n",
        "\n",
        "        est0 = run_kalman_filter_script(t0, F.item(), H.item(), R.item(), Q.item(),device).cpu().numpy()\n",
        "        est1 = run_kalman_filter_script(t1, F.item(), H.item(), R.item(), Q.item(),device).cpu().numpy()\n",
        "\n",
        "        kalman_series0.append(est0)\n",
        "        kalman_series1.append(est1)\n",
        "\n",
        "    return kalman_series0, kalman_series1, raw_series0, raw_series1\n",
        "\n",
        "def extract_kalman_test_single(X_test,device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),logger=None):\n",
        "    # Main loop\n",
        "    kalman_series0 = []\n",
        "    kalman_series1 = []\n",
        "    raw_series0 = []\n",
        "    raw_series1 = []\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "    single = [X_test]\n",
        "\n",
        "        # Kalman filter constants as tensors (still used outside JIT)\n",
        "    F = torch.tensor(1.0, device=device)\n",
        "    H = torch.tensor(1.0, device=device)\n",
        "    R = torch.tensor(1.0, device=device)\n",
        "    Q = torch.tensor(1e-5, device=device)\n",
        "\n",
        "    for i,series in enumerate(single):\n",
        "\n",
        "\n",
        "\n",
        "        t0 = torch.tensor(series[series.period == 0].value.values, dtype=torch.float32, device=device)\n",
        "        t1 = torch.tensor(series[series.period == 1].value.values, dtype=torch.float32, device=device)\n",
        "        raw_series0.append(t0)\n",
        "        raw_series1.append(t1)\n",
        "\n",
        "        est0 = run_kalman_filter_script(t0, F.item(), H.item(), R.item(), Q.item(),device).cpu().numpy()\n",
        "        est1 = run_kalman_filter_script(t1, F.item(), H.item(), R.item(), Q.item(),device).cpu().numpy()\n",
        "\n",
        "        kalman_series0.append(est0)\n",
        "        kalman_series1.append(est1)\n",
        "\n",
        "    return kalman_series0, kalman_series1, raw_series0, raw_series1\n",
        "\n"
      ],
      "metadata": {
        "id": "q30uXWYs1qRu"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def fast_ema(x, span):\n",
        "    alpha = 2/(span+1)\n",
        "    ema = np.empty_like(x)\n",
        "    ema[0] = x[0]\n",
        "    for i in range(1, len(x)):\n",
        "        ema[i] = alpha * x[i] + (1-alpha) * ema[i-1]\n",
        "    return ema[-1]\n",
        "\n",
        "def extract_features(a, b):\n",
        "    features = {}\n",
        "\n",
        "    # Basic statistics\n",
        "    features['mean_a'] = np.mean(a)\n",
        "    features['mean_b'] = np.mean(b)\n",
        "    features['std_a'] = np.std(a)\n",
        "    features['std_b'] = np.std(b)\n",
        "    features['skew_a'] = skew(a)\n",
        "    features['skew_b'] = skew(b)\n",
        "    features['kurt_a'] = kurtosis(a)\n",
        "    features['kurt_b'] = kurtosis(b)\n",
        "    features['iqr_a'] = iqr(a)\n",
        "    features['iqr_b'] = iqr(b)\n",
        "    features['std_ratio'] = features['std_b'] / (features['std_a'] + 1e-10)  # avoid div0\n",
        "\n",
        "    # Fit t-distribution (consider sampling if large arrays)\n",
        "    params_a = scipy.stats.t.fit(a)\n",
        "    params_b = scipy.stats.t.fit(b)\n",
        "    features['t_val_a'] = params_a[0]\n",
        "    features['t_mu_a'] = params_a[1]\n",
        "    features['t_sigma_a'] = params_a[2]\n",
        "    features['t_val_b'] = params_b[0]\n",
        "    features['t_mu_b'] = params_b[1]\n",
        "    features['t_sigma_b'] = params_b[2]\n",
        "\n",
        "    # Differences\n",
        "    features['mean_diff'] = features['mean_b'] - features['mean_a']\n",
        "    features['std_diff'] = features['std_b'] - features['std_a']\n",
        "\n",
        "\n",
        "    # EMA features (use fast_ema)\n",
        "    ema_windows = [5, 10, 15, 20, 30, 35, 40]\n",
        "    for w in ema_windows:\n",
        "        ema_a = fast_ema(a, w)\n",
        "        ema_b = fast_ema(b, w)\n",
        "        features[f'ema{w}_a'] = ema_a\n",
        "        features[f'ema{w}_b'] = ema_b\n",
        "        features[f'ema{w}_diff'] = ema_b - ema_a\n",
        "\n",
        "    # Cross-correlation\n",
        "    min_len = min(len(a), len(b))\n",
        "    a = a[:min_len]\n",
        "    b = b[:min_len]\n",
        "    max_lag = min(10, min_len - 1)\n",
        "    xcorr = []\n",
        "    for lag in range(1, max_lag + 1):\n",
        "        corr = np.corrcoef(a[:-lag], b[lag:])[0, 1]\n",
        "        xcorr.append(corr)\n",
        "\n",
        "    features['max_xcorr'] = np.nanmax(xcorr)\n",
        "    features['mean_xcorr'] = np.nanmean(xcorr)\n",
        "\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "dmZFeH70DiHG"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Your model definitions (from your code above) ===\n",
        "\n",
        "class LSTMEncoder(nn.Module):\n",
        "    def __init__(self, input_dim=2, hidden_dim=64, latent_dim=32, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        _, (h_n, _) = self.lstm(packed)\n",
        "        last_hidden = h_n[-1]  # shape: (B, hidden_dim)\n",
        "        z = self.fc(last_hidden)  # shape: (B, latent_dim)\n",
        "        return z\n",
        "\n",
        "class LSTMDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim=32, hidden_dim=64, output_dim=2, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.lstm = nn.LSTM(output_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.output_proj = nn.Linear(hidden_dim, output_dim)\n",
        "        self.num_layers = num_layers  # 🔧 Store number of layers\n",
        "\n",
        "    def forward(self, z, target_len):\n",
        "        batch_size = z.size(0)\n",
        "        hidden = self.fc(z).unsqueeze(0).repeat(self.num_layers, 1, 1)  # ✅ Use self.num_layers\n",
        "        cell = torch.zeros_like(hidden)\n",
        "\n",
        "        decoder_input = torch.zeros(batch_size, target_len, 2, device=z.device)\n",
        "        out, _ = self.lstm(decoder_input, (hidden, cell))\n",
        "        out = self.output_proj(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class LSTMAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim=2, hidden_dim=64, latent_dim=32, num_layers=5):\n",
        "        super().__init__()\n",
        "        self.encoder = LSTMEncoder(input_dim, hidden_dim, latent_dim, num_layers)\n",
        "        self.decoder = LSTMDecoder(latent_dim, hidden_dim, input_dim, num_layers)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        z = self.encoder(x, lengths)\n",
        "        max_len = x.size(1)\n",
        "        reconstructed = self.decoder(z, max_len)\n",
        "        return reconstructed, z\n",
        "\n",
        "# def regime_autoencoder(params=None, **kwargs):\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#     model = LSTMAutoencoder().to(device)\n",
        "#     return model"
      ],
      "metadata": {
        "id": "UB8y8vW9DiDj"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CNNEncoder(nn.Module):\n",
        "    def __init__(self, input_dim=2, hidden_channels=64, latent_dim=32):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(input_dim, hidden_channels, kernel_size=3, padding=1),  # Layer 1\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_channels, hidden_channels, kernel_size=3, padding=1),  # Layer 2\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_channels, hidden_channels, kernel_size=3, padding=1),  # Layer 3\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_channels, hidden_channels, kernel_size=3, padding=1),  # Layer 4\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.attn = nn.MultiheadAttention(embed_dim=hidden_channels, num_heads=4, batch_first=True)\n",
        "        self.proj = nn.Linear(hidden_channels, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)  # (B, 2, T) → (B, C=2, T)\n",
        "        conv_out = self.conv(x)  # (B, 64, T)\n",
        "        conv_out = conv_out.transpose(1, 2)  # (B, T, 64)\n",
        "        attn_out, _ = self.attn(conv_out, conv_out, conv_out)  # (B, T, 64)\n",
        "        pooled = attn_out.mean(dim=1)  # Global average pooling over time\n",
        "        z = self.proj(pooled)  # (B, latent_dim)\n",
        "        return z\n",
        "\n",
        "\n",
        "class CNNDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim=32, hidden_dim=64, output_dim=2):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.upsample_conv = nn.Conv1d(hidden_dim, 64, kernel_size=3, padding=1)\n",
        "\n",
        "        self.final_conv = nn.Sequential(\n",
        "            nn.Conv1d(64, hidden_dim, kernel_size=3, padding=1),  # Layer 1\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1),  # Layer 2\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1),  # Layer 3\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, output_dim, kernel_size=3, padding=1),  # Layer 4\n",
        "        )\n",
        "\n",
        "    def forward(self, z, target_len):\n",
        "        batch_size = z.size(0)\n",
        "        hidden = self.fc(z)  # (B, hidden_dim)\n",
        "        repeated = hidden.unsqueeze(2).repeat(1, 1, target_len)  # (B, hidden_dim, T)\n",
        "        upsampled = self.upsample_conv(repeated)  # (B, 64, T)\n",
        "        out = self.final_conv(upsampled)  # (B, 2, T)\n",
        "        return out.transpose(1, 2)  # (B, T, 2)\n",
        "\n",
        "class CNNAutoencoder(nn.Module):\n",
        "    def __init__(self, input_dim=2, latent_dim=32):\n",
        "        super().__init__()\n",
        "        self.encoder = CNNEncoder(input_dim=input_dim, latent_dim=latent_dim)\n",
        "        self.decoder = CNNDecoder(latent_dim=latent_dim)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        z = self.encoder(x)\n",
        "        max_len = x.size(1)\n",
        "        recon = self.decoder(z, max_len)\n",
        "        return recon, z\n",
        "\n",
        "def regime_autoencoder(**kwargs):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = CNNAutoencoder().to(device)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "dgJrn_6vAGbz"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_series(X_train, device=None, logger=None):\n",
        "    device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    index_x = X_train.index.get_level_values(0).unique().tolist()\n",
        "    raw_series0, raw_series1 = [], []\n",
        "\n",
        "    for i in index_x:\n",
        "        if (i % 100 == 0) and logger:\n",
        "            logger.info(f\"Estimating Kalman series for {i}-th series, time taken: {time.time() - start_time:.2f}s\")\n",
        "            start_time = time.time()\n",
        "\n",
        "        series = X_train.loc[i]\n",
        "        t0 = torch.tensor(series[series.period == 0].value.values, dtype=torch.float32).to(device)\n",
        "        t1 = torch.tensor(series[series.period == 1].value.values, dtype=torch.float32).to(device)\n",
        "        raw_series0.append(t0)\n",
        "        raw_series1.append(t1)\n",
        "\n",
        "    return raw_series0, raw_series1\n",
        "\n",
        "def collate_fn(batch):\n",
        "    if len(batch[0]) == 3:\n",
        "        s0, s1, labels = zip(*batch)\n",
        "        labels = torch.stack(labels)\n",
        "    else:\n",
        "        s0, s1 = zip(*batch)\n",
        "        labels = None\n",
        "\n",
        "    # Get actual lengths\n",
        "    len0 = torch.tensor([len(x) for x in s0])\n",
        "    len1 = torch.tensor([len(x) for x in s1])\n",
        "\n",
        "    # Use min length to truncate all\n",
        "    min_len = min(min(len0), min(len1))\n",
        "    s0_trunc = [x[:min_len] for x in s0]\n",
        "    s1_trunc = [x[:min_len] for x in s1]\n",
        "\n",
        "    # Update lengths since everything is truncated to min_len\n",
        "    updated_lengths = torch.full((len(s0),), fill_value=min_len, dtype=torch.long)\n",
        "\n",
        "    # Stack and combine\n",
        "    pad0 = torch.stack(s0_trunc).unsqueeze(-1)  # (B, T, 1)\n",
        "    pad1 = torch.stack(s1_trunc).unsqueeze(-1)  # (B, T, 1)\n",
        "    combined = torch.cat([pad0, pad1], dim=-1)  # (B, T, 2)\n",
        "\n",
        "    if labels is not None:\n",
        "        return combined, updated_lengths, labels\n",
        "    else:\n",
        "        return combined, updated_lengths\n",
        "\n",
        "# === Custom Dataset ===\n",
        "class RegimePairDataset(Dataset):\n",
        "    def __init__(self, raw_0, raw_1, labels=None):\n",
        "        self.data = []\n",
        "        self.has_labels = labels is not None\n",
        "\n",
        "        if self.has_labels:\n",
        "            for r0, r1, label in zip(raw_0, raw_1, labels):\n",
        "                r0 = r0.cpu() if isinstance(r0, torch.Tensor) else torch.tensor(r0, dtype=torch.float32)\n",
        "                r1 = r1.cpu() if isinstance(r1, torch.Tensor) else torch.tensor(r1, dtype=torch.float32)\n",
        "                self.data.append((r0, r1, torch.tensor(label, dtype=torch.float32)))\n",
        "        else:\n",
        "            for r0, r1 in zip(raw_0, raw_1):\n",
        "                r0 = r0.cpu() if isinstance(r0, torch.Tensor) else torch.tensor(r0, dtype=torch.float32)\n",
        "                r1 = r1.cpu() if isinstance(r1, torch.Tensor) else torch.tensor(r1, dtype=torch.float32)\n",
        "                self.data.append((r0, r1))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "\n",
        "# === DataLoader Creator ===\n",
        "def create_data_loaders(X_train,y_train=None):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    #r0, r1 = extract_series(X_train, device=device, logger=None)\n",
        "    k0, k1, r0, r1 = extract_kalman(X_train, device=device, logger=None)\n",
        "\n",
        "    pair_dataset = RegimePairDataset(r0, r1, y_train)\n",
        "    kalman_dataset = RegimePairDataset(k0, k1, y_train)\n",
        "\n",
        "    train_size = int(0.8*len(pair_dataset))\n",
        "    val_size = len(pair_dataset) - train_size\n",
        "    generator = torch.Generator().manual_seed(42)\n",
        "\n",
        "    train_dataset, val_dataset = random_split(pair_dataset, [train_size, val_size], generator=generator)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, sampler=None,\n",
        "                              num_workers=max(2, cpu_count()), pin_memory=True, persistent_workers=True, prefetch_factor=4,\n",
        "                              collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=64, sampler=None,\n",
        "                           num_workers=max(2, cpu_count()), pin_memory=True, persistent_workers=True, prefetch_factor=4,\n",
        "                            collate_fn=collate_fn)\n",
        "\n",
        "    complete_loader = DataLoader(pair_dataset, batch_size=64, sampler=None,\n",
        "                           num_workers=max(2, cpu_count()), pin_memory=True, persistent_workers=True, prefetch_factor=4,\n",
        "                            collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "    k_train_size = int(0.8*len(kalman_dataset))\n",
        "    k_val_size = len(kalman_dataset) - k_train_size\n",
        "    generator = torch.Generator().manual_seed(42)\n",
        "\n",
        "    k_train_dataset, k_val_dataset = random_split(kalman_dataset, [k_train_size, k_val_size], generator=generator)\n",
        "\n",
        "    k_train_loader = DataLoader(k_train_dataset, batch_size=64, sampler=None,\n",
        "                              num_workers=max(2, cpu_count()), pin_memory=True, persistent_workers=True, prefetch_factor=4,\n",
        "                              collate_fn=collate_fn)\n",
        "    k_val_loader = DataLoader(k_val_dataset, batch_size=64, sampler=None,\n",
        "                           num_workers=max(2, cpu_count()), pin_memory=True, persistent_workers=True, prefetch_factor=4,\n",
        "                            collate_fn=collate_fn)\n",
        "\n",
        "    k_complete_loader = DataLoader(kalman_dataset, batch_size=64, sampler=None,\n",
        "                           num_workers=max(2, cpu_count()), pin_memory=True, persistent_workers=True, prefetch_factor=4,\n",
        "                            collate_fn=collate_fn)\n",
        "\n",
        "    return train_loader, val_loader, complete_loader, k_train_loader, k_val_loader, k_complete_loader\n",
        "\n",
        "\n",
        "def create_test_data_loaders(X_test):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    k0, k1, r0, r1 = extract_kalman_test_single(X_test, device=device, logger=None)\n",
        "    pair_dataset = RegimePairDataset(r0, r1)\n",
        "    kalman_dataset = RegimePairDataset(k0, k1)\n",
        "\n",
        "    complete_loader = DataLoader(pair_dataset, batch_size=64, sampler=None,\n",
        "                           num_workers=0, pin_memory=True,# persistent_workers=True, prefetch_factor=4,\n",
        "                            collate_fn=collate_fn)\n",
        "\n",
        "    k_complete_loader = DataLoader(kalman_dataset, batch_size=64, sampler=None,\n",
        "                        num_workers=0, pin_memory=True,# persistent_workers=True, prefetch_factor=4,\n",
        "                        collate_fn=collate_fn)\n",
        "\n",
        "    return complete_loader, k_complete_loader\n"
      ],
      "metadata": {
        "id": "zt6QwOJxDh_m"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI5dH8ffRSx9",
        "outputId": "1964d655-8e89-4696-e8d0-5a16b931b884"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model, optimizer, scheduler, loss_func, train_data_loader, val_data_loader, dir_name,filename='latest_model_vae.ckpt'):\n",
        "        os.makedirs(dir_name, exist_ok=True)\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.loss_func = loss_func\n",
        "        self.train_data_loader = train_data_loader\n",
        "        self.val_data_loader = val_data_loader\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "        self.logs = {}\n",
        "        self.startEpoch = 0\n",
        "        self.epoch = 0\n",
        "        self.iters = 0\n",
        "        self.dir_name = dir_name\n",
        "        self.filename = filename\n",
        "\n",
        "    def train(self):\n",
        "        best_loss = float('inf')\n",
        "        best_epoch = 0\n",
        "        self.logs['best_epoch'] = best_epoch\n",
        "        self.logs['best_val_loss'] = best_loss\n",
        "\n",
        "        for epoch in range(self.startEpoch, 200):\n",
        "            self.epoch = epoch\n",
        "            start = time.time()\n",
        "            print(f\"Starting with epoch{epoch} and time taken is {time.time() - start}\")\n",
        "\n",
        "            tr_time = self.train_one_epoch()\n",
        "            val_loss, val_time = self.compute_validation_loss()\n",
        "\n",
        "            self.scheduler.step()\n",
        "\n",
        "            is_best_loss = val_loss < best_loss\n",
        "            if is_best_loss:\n",
        "                best_loss = val_loss\n",
        "                best_epoch = epoch\n",
        "                path = os.path.join(self.dir_name,self.filename)\n",
        "                self.save_checkpoint(path)\n",
        "\n",
        "            self.logs['train_loss'] = self.train_loss\n",
        "            self.logs['val_loss'] = val_loss\n",
        "            self.logs['best_val_loss'] = best_loss\n",
        "            self.logs['best_epoch'] = best_epoch\n",
        "\n",
        "    def train_one_epoch(self):\n",
        "        self.model.train()\n",
        "        tr_time = 0\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for i,batch in enumerate(self.train_data_loader):\n",
        "\n",
        "            combined, lengths, labels = batch\n",
        "            combined = combined.to(self.device)\n",
        "            lengths = lengths.to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            tr_start = time.time()\n",
        "            recon_x, _ = self.model(combined, lengths)\n",
        "            loss = self.loss_func(recon_x, combined)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            tr_time += time.time() - tr_start\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        self.train_loss = total_loss / len(self.train_data_loader)\n",
        "        return tr_time\n",
        "\n",
        "    def compute_validation_loss(self):\n",
        "        self.model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_time = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in self.val_data_loader:\n",
        "                combined, lengths, labels = batch\n",
        "                combined = combined.to(self.device)\n",
        "                lengths = lengths.to(self.device)\n",
        "\n",
        "                val_start = time.time()\n",
        "                recon_x, _ = self.model(combined, lengths)\n",
        "                loss = self.loss_func(recon_x, combined)\n",
        "                val_loss += loss.item()\n",
        "                val_time += time.time() - val_start\n",
        "\n",
        "        val_loss /= len(self.val_data_loader)\n",
        "        return val_loss, val_time\n",
        "\n",
        "    def save_checkpoint(self, path):\n",
        "        torch.save({\n",
        "            'epoch': self.epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
        "            'best_val_loss': self.logs['best_val_loss'],\n",
        "        }, path)\n"
      ],
      "metadata": {
        "id": "eQEPpANtG3O0"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_chunk(temp):\n",
        "  t0_series = temp[temp.period == 0].value.values\n",
        "  t1_series = temp[temp.period == 1].value.values\n",
        "  features_v = extract_features(t0_series, t1_series)\n",
        "  return features_v\n",
        "\n",
        "def process_wrapper(i_X):\n",
        "    i, X = i_X\n",
        "    if i%100 == 0:\n",
        "        print(f\"presently running {i} data item to extract\")\n",
        "    return i, process_chunk(X.loc[i])"
      ],
      "metadata": {
        "id": "bPmPKZLPKamV"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-18T10:04:00.459399Z",
          "start_time": "2024-11-18T10:04:00.455716Z"
        },
        "id": "xQwWDC6M-0fT"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    X_train: pd.DataFrame,\n",
        "    y_train: pd.Series,\n",
        "    model_directory_path: str,\n",
        "):\n",
        "\n",
        "    os.makedirs(model_directory_path, exist_ok=True)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_rnn = regime_autoencoder().to(device)\n",
        "    train_data_loader, val_data_loader,complete_data_loader, k_train_data_loader, k_val_data_loader, k_complete_data_loader = create_data_loaders(X_train,y_train)\n",
        "\n",
        "    optimizer = optim.Adam(model_rnn.parameters(), lr=1e-4)\n",
        "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
        "\n",
        "    loss_func = torch.nn.MSELoss()\n",
        "\n",
        "    filename = 'checkpoint_raw_data.ckpt'\n",
        "\n",
        "    trainer = Trainer(model_rnn, optimizer, scheduler, loss_func, train_data_loader, val_data_loader,model_directory_path,filename)\n",
        "    trainer.train()\n",
        "\n",
        "    model_rnn_updated = trainer.model\n",
        "\n",
        "    z = []\n",
        "\n",
        "    for batch in complete_data_loader:\n",
        "        combined, lengths, labels = batch\n",
        "        combined = combined.to(device)\n",
        "        lengths = lengths.to(device)\n",
        "\n",
        "        recon_x, latent = model_rnn_updated(combined, lengths)  # assuming \"_\" is the latent vector\n",
        "        z.append(latent.detach().cpu().numpy())     # detach, move to CPU, convert to numpy\n",
        "\n",
        "    z = np.concatenate(z, axis=0)  # shape: (total_samples, latent_dim)\n",
        "\n",
        "    latent_feature_names = [f\"z_{i}\" for i in range(z.shape[1])]\n",
        "\n",
        "\n",
        "    k_model_rnn = regime_autoencoder().to(device)\n",
        "\n",
        "    optimizer = optim.Adam(k_model_rnn.parameters(), lr=1e-4)\n",
        "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
        "\n",
        "    loss_func = torch.nn.MSELoss()\n",
        "\n",
        "    k_filename = 'checkpoint_kalman_data.ckpt'\n",
        "\n",
        "    trainer = Trainer(k_model_rnn, optimizer, scheduler, loss_func, k_train_data_loader, k_val_data_loader,model_directory_path,k_filename)\n",
        "    trainer.train()\n",
        "\n",
        "    k_model_rnn_updated = trainer.model\n",
        "\n",
        "    k_z = []\n",
        "\n",
        "    for batch in k_complete_data_loader:\n",
        "        combined, lengths, labels = batch\n",
        "        combined = combined.to(device)\n",
        "        lengths = lengths.to(device)\n",
        "\n",
        "        recon_x, latent = k_model_rnn_updated(combined, lengths)  # assuming \"_\" is the latent vector\n",
        "        k_z.append(latent.detach().cpu().numpy())     # detach, move to CPU, convert to numpy\n",
        "\n",
        "    k_z = np.concatenate(k_z, axis=0)  # shape: (total_samples, latent_dim)\n",
        "\n",
        "    k_latent_feature_names = [f\"k_{i}\" for i in range(k_z.shape[1])]\n",
        "\n",
        "\n",
        "    index_x = X_train.index.get_level_values(0).unique().tolist()\n",
        "\n",
        "    print(f\"Spawning {cpu_count()} parallel workers...\")\n",
        "\n",
        "    # Prepare iterable of (i, X) tuples\n",
        "    args = [(i, X_train) for i in index_x]\n",
        "\n",
        "    with Pool(processes=cpu_count()) as pool:\n",
        "        results = list(pool.imap_unordered(process_wrapper, args, chunksize=50))\n",
        "\n",
        "    # Unpack results\n",
        "    index_x, features_list = zip(*results)\n",
        "\n",
        "    data = pd.DataFrame.from_records(features_list, index=index_x)\n",
        "    data.index.name = \"time\"\n",
        "\n",
        "    print(f\"shape of data is {data.shape} and len is {len(index_x)}\")\n",
        "    z_df = pd.DataFrame(z, index=data.index,columns=latent_feature_names)  # ensure the index matches\n",
        "    k_z_df = pd.DataFrame(k_z, index=data.index,columns=k_latent_feature_names)  # ensure the index matches\n",
        "\n",
        "    df_new = pd.concat([data, z_df], axis=1)\n",
        "    df_new = pd.concat([df_new, k_z_df], axis=1)\n",
        "\n",
        "    n_trials = 500   # number of Optuna trials\n",
        "    cv = 3\n",
        "\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 20, 400,step=20),\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 18,step=3),\n",
        "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.2),\n",
        "            'subsample': trial.suggest_float('subsample', 0.8, 1.0),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.8, 1.0),\n",
        "            'gamma': trial.suggest_float('gamma', 0, 1),\n",
        "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
        "            'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
        "            'reg_lambda': trial.suggest_loguniform('reg_lambda', 1.0, 3.0),\n",
        "            'scale_pos_weight': trial.suggest_categorical('scale_pos_weight', [1, 3, 5, 10]),\n",
        "            'eval_metric': 'auc',\n",
        "            'use_label_encoder': False,\n",
        "            'random_state': 42,\n",
        "        }\n",
        "\n",
        "        clf = XGBClassifier(**params)\n",
        "\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('clf', clf)\n",
        "        ])\n",
        "\n",
        "        scores = cross_val_score(pipeline, df_new, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
        "        return scores.mean()\n",
        "\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "    print(f\"  Value: {trial.value}\")\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(f\"    {key}: {value}\")\n",
        "\n",
        "    # Train best model on full data\n",
        "    best_params = trial.params\n",
        "    best_params['eval_metric'] = 'auc'\n",
        "    best_params['use_label_encoder'] = False\n",
        "    best_params['random_state'] = 42\n",
        "\n",
        "    best_clf = XGBClassifier(**best_params)\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', best_clf)\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(df_new, y_train)\n",
        "\n",
        "    os.makedirs(model_directory_path, exist_ok=True)\n",
        "\n",
        "    joblib.dump(df_new.columns.tolist(), os.path.join(model_directory_path, \"feature_names.joblib\"))\n",
        "\n",
        "\n",
        "    joblib.dump(pipeline, os.path.join(model_directory_path, 'model_with_rnn_results.joblib'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n-jboJH-0fU"
      },
      "source": [
        "### The `infer()` Function\n",
        "\n",
        "In the inference function, your trained model (if any) is loaded and used to make predictions on test data.\n",
        "\n",
        "**Important workflow:**\n",
        "1. Load your model;\n",
        "2. Use the `yield` statement to signal readiness to the runner;\n",
        "3. Process each dataset one by one within the for loop;\n",
        "4. For each dataset, use `yield prediction` to return your prediction.\n",
        "\n",
        "**Note:** The datasets can only be iterated once!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-11-18T10:03:59.120294Z",
          "start_time": "2024-11-18T10:03:59.114830Z"
        },
        "id": "r1b7hRkl-0fU"
      },
      "outputs": [],
      "source": [
        "def infer(\n",
        "    X_test: typing.Iterable[pd.DataFrame],\n",
        "    model_directory_path: str,\n",
        "):\n",
        "    model_xgb = joblib.load(os.path.join(model_directory_path, 'model_with_rnn_results.joblib'))\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # Load the model\n",
        "    model_rnn = regime_autoencoder().to(device)\n",
        "\n",
        "    checkpoint_path = os.path.join(model_directory_path,'checkpoint_raw_data.ckpt')\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    # Attempt to load the model state dict\n",
        "    try:\n",
        "        model_rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    except RuntimeError as e:\n",
        "        print(\"RuntimeError caught, trying to fix state dict keys...\")\n",
        "        new_state_dict = OrderedDict()\n",
        "        for key, val in checkpoint['model_state_dict'].items():\n",
        "            new_key = key\n",
        "            if key.startswith(\"module.\"):  # typical of DDP-wrapped models\n",
        "                new_key = key[7:]\n",
        "            new_state_dict[new_key] = val\n",
        "        model_rnn.load_state_dict(new_state_dict)\n",
        "\n",
        "    model_rnn = model_rnn.eval()\n",
        "\n",
        "    k_model_rnn = regime_autoencoder().to(device)\n",
        "\n",
        "    checkpoint_path = os.path.join(model_directory_path,'checkpoint_kalman_data.ckpt')\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    # Attempt to load the model state dict\n",
        "    try:\n",
        "        k_model_rnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    except RuntimeError as e:\n",
        "        print(\"RuntimeError caught, trying to fix state dict keys...\")\n",
        "        new_state_dict = OrderedDict()\n",
        "        for key, val in checkpoint['model_state_dict'].items():\n",
        "            new_key = key\n",
        "            if key.startswith(\"module.\"):  # typical of DDP-wrapped models\n",
        "                new_key = key[7:]\n",
        "            new_state_dict[new_key] = val\n",
        "        k_model_rnn.load_state_dict(new_state_dict)\n",
        "\n",
        "    k_model_rnn = k_model_rnn.eval()\n",
        "\n",
        "\n",
        "    feature_names_path = os.path.join(model_directory_path, \"feature_names.joblib\")\n",
        "    feature_names = joblib.load(feature_names_path)\n",
        "\n",
        "    yield  # Mark as ready\n",
        "\n",
        "    # X_test can only be iterated once.\n",
        "    # Before getting the next dataset, you must predict the current one.\n",
        "    for dataset in X_test:\n",
        "      test_dataset, k_test_dataset = create_test_data_loaders(dataset)\n",
        "\n",
        "      z = []\n",
        "\n",
        "      for batch in test_dataset:\n",
        "          combined, lengths = batch\n",
        "          combined = combined.to(device)\n",
        "          lengths = lengths.to(device)\n",
        "\n",
        "          recon_x, latent = model_rnn(combined, lengths)  # assuming \"_\" is the latent vector\n",
        "          z.append(latent.detach().cpu().numpy())     # detach, move to CPU, convert to numpy\n",
        "\n",
        "      z = np.concatenate(z, axis=0)  # shape: (total_samples, latent_dim)\n",
        "      latent_feature_names = [f\"z_{i}\" for i in range(z.shape[1])]\n",
        "\n",
        "\n",
        "\n",
        "      k_z = []\n",
        "\n",
        "      for batch in k_test_dataset:\n",
        "          combined, lengths = batch\n",
        "          combined = combined.to(device)\n",
        "          lengths = lengths.to(device)\n",
        "\n",
        "          recon_x, latent = model_rnn(combined, lengths)  # assuming \"_\" is the latent vector\n",
        "          k_z.append(latent.detach().cpu().numpy())     # detach, move to CPU, convert to numpy\n",
        "\n",
        "      k_z = np.concatenate(k_z, axis=0)  # shape: (total_samples, latent_dim)\n",
        "      k_latent_feature_names = [f\"k_{i}\" for i in range(z.shape[1])]\n",
        "\n",
        "\n",
        "      features = process_chunk(dataset)\n",
        "      features_df = pd.DataFrame([features])\n",
        "\n",
        "      z_df = pd.DataFrame(z, index=features_df.index,columns=latent_feature_names)  # ensure the index matches\n",
        "\n",
        "      k_z_df = pd.DataFrame(k_z, index=features_df.index,columns=k_latent_feature_names)  # ensure the index matches\n",
        "\n",
        "      df_new = pd.concat([features_df, z_df], axis=1)\n",
        "      df_new = pd.concat([df_new, k_z_df], axis=1)\n",
        "      df_new.columns = df_new.columns.astype(str)\n",
        "\n",
        "      prediction = model_xgb.predict_proba(df_new)[0, 1]\n",
        "\n",
        "      yield prediction  # Send the prediction for the current dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W0Kl9CA-0fU"
      },
      "source": [
        "## Local testing\n",
        "\n",
        "To make sure your `train()` and `infer()` function are working properly, you can call the `crunch.test()` function that will reproduce the cloud environment locally. <br />\n",
        "Even if it is not perfect, it should give you a quick idea if your model is working properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDZeP-4--0fU",
        "outputId": "b057f6d6-3d8f-40d4-fa7c-ee62f253ccfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "23:49:03 no forbidden library found\n",
            "23:49:03 \n",
            "23:49:03 started\n",
            "23:49:03 running local test\n",
            "23:49:03 internet access isn't restricted, no check will be done\n",
            "23:49:03 \n",
            "23:49:04 starting unstructured loop...\n",
            "23:49:04 executing - command=train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/X_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/X_train.parquet (204327238 bytes)\n",
            "data/X_train.parquet: already exists, file length match\n",
            "data/X_test.reduced.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/X_test.reduced.parquet (2380918 bytes)\n",
            "data/X_test.reduced.parquet: already exists, file length match\n",
            "data/y_train.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/y_train.parquet (61003 bytes)\n",
            "data/y_train.parquet: already exists, file length match\n",
            "data/y_test.reduced.parquet: download from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/146/y_test.reduced.parquet (2655 bytes)\n",
            "data/y_test.reduced.parquet: already exists, file length match\n",
            "Estimating Kalman series for 0-th series, time taken: 0.00s\n",
            "Starting with epoch0 and time taken is 2.1457672119140625e-06\n",
            "Starting with epoch0 and time taken is 4.5299530029296875e-06\n",
            "Spawning 2 parallel workers...\n",
            "presently running 0 data item to extract\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-08 23:49:58,622] A new study created in memory with name: no-name-6485a818-58d9-4c05-a331-c57f690928b4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of data is (100, 36) and len is 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-90-67ca56d73f2f>:101: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.2),\n",
            "<ipython-input-90-67ca56d73f2f>:106: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
            "<ipython-input-90-67ca56d73f2f>:107: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1.0, 3.0),\n",
            "[I 2025-06-08 23:50:01,646] Trial 0 finished with value: 0.5732323232323232 and parameters: {'n_estimators': 120, 'max_depth': 3, 'learning_rate': 0.03053426364428258, 'subsample': 0.9715482763067447, 'colsample_bytree': 0.852173641914004, 'gamma': 0.9965740954230347, 'min_child_weight': 7, 'reg_alpha': 1.9864567686261256e-07, 'reg_lambda': 1.265206270455619, 'scale_pos_weight': 1}. Best is trial 0 with value: 0.5732323232323232.\n",
            "<ipython-input-90-67ca56d73f2f>:101: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.2),\n",
            "<ipython-input-90-67ca56d73f2f>:106: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
            "<ipython-input-90-67ca56d73f2f>:107: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1.0, 3.0),\n",
            "[I 2025-06-08 23:50:01,983] Trial 1 finished with value: 0.5630165289256198 and parameters: {'n_estimators': 160, 'max_depth': 9, 'learning_rate': 0.0032760187441859406, 'subsample': 0.7064580103904677, 'colsample_bytree': 0.9699517589154213, 'gamma': 0.23776963259146455, 'min_child_weight': 7, 'reg_alpha': 0.4880236708045512, 'reg_lambda': 1.7754036764517909, 'scale_pos_weight': 5}. Best is trial 0 with value: 0.5732323232323232.\n",
            "<ipython-input-90-67ca56d73f2f>:101: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.2),\n",
            "<ipython-input-90-67ca56d73f2f>:106: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
            "<ipython-input-90-67ca56d73f2f>:107: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1.0, 3.0),\n",
            "[I 2025-06-08 23:50:02,484] Trial 2 finished with value: 0.6790633608815427 and parameters: {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.0019331858278767693, 'subsample': 0.9168129808976612, 'colsample_bytree': 0.8553677420175932, 'gamma': 0.7365644629477931, 'min_child_weight': 3, 'reg_alpha': 0.000506357335962476, 'reg_lambda': 2.0754865387040797, 'scale_pos_weight': 3}. Best is trial 2 with value: 0.6790633608815427.\n",
            "<ipython-input-90-67ca56d73f2f>:101: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.2),\n",
            "<ipython-input-90-67ca56d73f2f>:106: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
            "<ipython-input-90-67ca56d73f2f>:107: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1.0, 3.0),\n",
            "[I 2025-06-08 23:50:02,690] Trial 3 finished with value: 0.6213269054178144 and parameters: {'n_estimators': 80, 'max_depth': 15, 'learning_rate': 0.10530978339735171, 'subsample': 0.9211673415365498, 'colsample_bytree': 0.9373863813482031, 'gamma': 0.8220460260164872, 'min_child_weight': 4, 'reg_alpha': 0.010753886716380738, 'reg_lambda': 2.3111638643968058, 'scale_pos_weight': 10}. Best is trial 2 with value: 0.6790633608815427.\n",
            "<ipython-input-90-67ca56d73f2f>:101: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.2),\n",
            "<ipython-input-90-67ca56d73f2f>:106: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
            "<ipython-input-90-67ca56d73f2f>:107: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1.0, 3.0),\n",
            "[I 2025-06-08 23:50:03,095] Trial 4 finished with value: 0.6854912764003673 and parameters: {'n_estimators': 140, 'max_depth': 15, 'learning_rate': 0.0032314595985013248, 'subsample': 0.8630908616227708, 'colsample_bytree': 0.9387815025389763, 'gamma': 0.20303372547475595, 'min_child_weight': 4, 'reg_alpha': 2.9467326536793902e-05, 'reg_lambda': 2.662383122190039, 'scale_pos_weight': 10}. Best is trial 4 with value: 0.6854912764003673.\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:50:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            "  Value: 0.6854912764003673\n",
            "  Params: \n",
            "    n_estimators: 140\n",
            "    max_depth: 15\n",
            "    learning_rate: 0.0032314595985013248\n",
            "    subsample: 0.8630908616227708\n",
            "    colsample_bytree: 0.9387815025389763\n",
            "    gamma: 0.20303372547475595\n",
            "    min_child_weight: 4\n",
            "    reg_alpha: 2.9467326536793902e-05\n",
            "    reg_lambda: 2.662383122190039\n",
            "    scale_pos_weight: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "23:50:04 executing - command=infer\n",
            "23:50:54 checking determinism by executing the inference again with 30% of the data (tolerance: 1e-08)\n",
            "23:50:54 executing - command=infer\n",
            "23:51:13 determinism check: passed\n",
            "23:51:13 save prediction - path=data/prediction.parquet\n",
            "23:51:13 ended\n",
            "23:51:13 duration - time=00:02:10\n",
            "23:51:13 memory - before=\"3.68 GB\" after=\"3.65 GB\" consumed=\"-24850432 bytes\"\n"
          ]
        }
      ],
      "source": [
        "crunch.test(\n",
        "    # Uncomment to disable the train\n",
        "    # force_first_train=False,\n",
        "\n",
        "    # Uncomment to disable the determinism check\n",
        "    # no_determinism_check=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV_5CKs--0fU"
      },
      "source": [
        "## Results\n",
        "\n",
        "Once the local tester is done, you can preview the result stored in `data/prediction.parquet`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly5q68sA-0fU"
      },
      "outputs": [],
      "source": [
        "prediction = pd.read_parquet(\"data/prediction.parquet\")\n",
        "prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oP-NLGh-0fU"
      },
      "source": [
        "### Local scoring\n",
        "\n",
        "You can call the function that the system uses to estimate your score locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyCrjpzv-0fU",
        "outputId": "6cabf91d-7bae-4168-8423-d6836eab5dae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.5103286384976525)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Load the targets\n",
        "target = pd.read_parquet(\"data/y_test.reduced.parquet\")[\"structural_breakpoint\"]\n",
        "\n",
        "# Call the scoring function\n",
        "sklearn.metrics.roc_auc_score(\n",
        "    target,\n",
        "    prediction,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AE1i3pR-0fV"
      },
      "source": [
        "# Submit your Notebook\n",
        "\n",
        "To submit your work, you must:\n",
        "1. Download your Notebook from Colab\n",
        "2. Upload it to the platform\n",
        "3. Create a run to validate it\n",
        "\n",
        "### >> https://hub.crunchdao.com/competitions/structural-break/submit/notebook\n",
        "\n",
        "![Download and Submit Notebook](https://raw.githubusercontent.com/crunchdao/competitions/refs/heads/master/documentation/animations/download-and-submit-notebook.gif)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}